{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx2Trt\n",
    "###### https://zhuanlan.zhihu.com/p/548006090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "from common import EXPLICIT_BATCH\n",
    "from common import allocate_buffers, do_inference_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engine(\n",
    "    onnx_path, \n",
    "    out_trt_path, \n",
    "    max_batch_size=1, \n",
    "    mode='fp32', \n",
    "    calib=None):\n",
    "    ''' convert onnx to tensorrt engine, use mode of ['fp32', 'fp16', 'int8']\n",
    "        : engine: 推理用到的模型\n",
    "        : builder: 用来构建engine\n",
    "        : config:\n",
    "        : parser: 用来解析onnx文件\n",
    "    : return: trt engine\n",
    "    '''\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    config = builder.create_builder_config()\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    \n",
    "    config.max_workspace_size = 1 << 30  # 最大显存占用\n",
    "    builder.max_batch_size = max_batch_size  # 推理的时候要保证batch_size<=max_batch_size\n",
    "    \n",
    "    if mode == 'int8':\n",
    "        assert (builder.platform_has_fast_int8 == True), \"not support int8\"\n",
    "        builder.int8_mode = True\n",
    "        builder.int8_calibrator = calib\n",
    "    elif mode == 'fp16':\n",
    "        assert (builder.platform_has_fast_fp16 == True), \"not support fp16\"\n",
    "        builder.fp16_mode = True\n",
    "    \n",
    "    # parse model file\n",
    "    print('Loading ONNX file from path {}...'.format(onnx_path))\n",
    "    with open(onnx_path, 'rb') as onnx_model:\n",
    "        print('Beginning ONNX file parsing')\n",
    "        parser.parse(onnx_model.read())\n",
    "    print('Completed parsing of ONNX file')\n",
    "    \n",
    "    # Dynamic input setting\n",
    "    network.get_input(0).shape=[-1, 3, -1, -1]\n",
    "    # 为每个动态输入绑定一个profile\n",
    "    # 设置最小的尺寸, 常用的尺寸, 最大的尺寸, 推理时候输入需要在这个范围内\n",
    "    profile = builder.create_optimization_profile()\n",
    "    profile.set_shape(\n",
    "        network.get_input(0).name, \n",
    "        (1, 3, 512, 512), \n",
    "        (1, 3, 1024, 1024), \n",
    "        (1, 3, 2048, 2048))\n",
    "    config.add_optimization_profile(profile)\n",
    "    \n",
    "    # build engine\n",
    "    print('Building an engine from file {}; this may take a while...'.format(onnx_path))\n",
    "    engine = builder.build_engine(network, config)\n",
    "    print(\"Created engine success! \")\n",
    "    \n",
    "    # save trt model\n",
    "    print('Saving TRT engine file to path {}...'.format(out_trt_path))\n",
    "    with open(out_trt_path, \"wb\") as f:\n",
    "        f.write(engine.serialize())   # 序列化（编码）-> 文件\n",
    "    print('Engine file has already saved to {}!'.format(out_trt_path))\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine(trt_path):\n",
    "    print(f'Reading engine from file {trt_path}')\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "    with open(trt_path,'rb') as f:\n",
    "        return runtime.deserialize_cuda_engine(f.read())  # 反序列化（解码）-> 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "onnx_path = \".../models/onnx/db_r18_op10_sim.onnx\"\n",
    "out_trt_path = \".../models/trt/db_r18.trt\"\n",
    "max_batch_size = 1\n",
    "mode = 'fp32'    # ['fp32', 'fp16', 'int8']\n",
    "if mode == 'int8':\n",
    "    # Note that: if use int8 mode, you should prepare a calibrate dataset and create a Calibrator class.\n",
    "    # In Calibrator class, you should override 'get_batch_size, get_batch',\n",
    "    # 'read_calibration_cache', 'write_calibration_cache'.\n",
    "    # You can reference implementation of CenterNetEntropyCalibrator.\n",
    "    calib = CustomEntropyCalibrator()  # TODO:自定义\n",
    "else:\n",
    "    calib = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to trt engine\n",
    "build_engine(onnx_path, out_trt_path, max_batch_size=max_batch_size, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from pytocr.modeling.architectures import build_model\n",
    "from pytocr.utils.save_load import load_pretrained_params\n",
    "from utils import load_config, draw_det_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose test image\n",
    "img_path = r\".../test_img.png\"\n",
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "resized_img = cv2.resize(img, (960, 736))\n",
    "image_data = np.array(resized_img, dtype='float32')\n",
    "image_data /= 255.\n",
    "image_data = np.transpose(image_data, (2, 0, 1))  # C H W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch model config\n",
    "config_path = \".../PyTorchOCR/configs/det/det_r18_db.yml\"\n",
    "model_path = \".../PyTorchOCR/models/torch/db_r18.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(config_path)\n",
    "config[\"Global\"][\"distributed\"] = False\n",
    "\n",
    "# build model\n",
    "model = build_model(config[\"Architecture\"])\n",
    "# check if set use_gpu=True in paddlepaddle cpu version\n",
    "use_gpu = config[\"Global\"][\"use_gpu\"] and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model = load_pretrained_params(model, model_path)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch infer\n",
    "torch_input = torch.from_numpy(image_data).unsqueeze(0)  # N C H W\n",
    "\n",
    "st_time = time.time()\n",
    "with torch.no_grad():\n",
    "    torch_input = torch_input.to(device)\n",
    "    print(torch_input.shape, torch_input.dtype)\n",
    "    torch_preds = model(torch_input)[\"maps\"].cpu().numpy()\n",
    "print(\"torch infer cost time\", time.time() - st_time)\n",
    "print(torch_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trt engine\n",
    "trt_path = out_trt_path\n",
    "engine = get_engine(trt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trt infer\n",
    "trt_input = np.expand_dims(image_data, 0)\n",
    "trt_input = np.ascontiguousarray(trt_input)\n",
    "height, width = trt_input.shape[-2:]\n",
    "\n",
    "context = engine.create_execution_context()\n",
    "# 修改allocate_buffers函数,支持动态输入\n",
    "inputs, outputs, bindings, stream = allocate_buffers(engine, (height, width))\n",
    "# 生成engine时指定了多个optimization profile，\n",
    "# 在实际使用的时候，必须指定使用哪个profile\n",
    "# profile是按照递增进行编码的。\n",
    "context.active_optimization_profile = 0  # 新增部分\n",
    "origin_inputshape = context.get_binding_shape(0)\n",
    "if origin_inputshape[-1] == -1:\n",
    "    origin_inputshape[-2], origin_inputshape[-1] = (height, width)\n",
    "    context.set_binding_shape(0, (origin_inputshape))\n",
    "\n",
    "print(f'Running inference on image {img_path}...')\n",
    "st_time = time.time()\n",
    "inputs[0].host = trt_input\n",
    "trt_preds = do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)[0]\n",
    "trt_preds = np.reshape(trt_preds, (max_batch_size, 1, height, width))[0]\n",
    "print(\"trt infer cost time\", time.time() - st_time)\n",
    "print(trt_preds.shape)\n",
    "# trt_outputs = np.reshape(trt_outputs,(height,width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算输出差异\n",
    "diff = trt_preds - torch_preds\n",
    "print(\"difference between onnx and torch: \", max(diff.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}